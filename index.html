<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="PAPER_TITLE - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>ABCD</title>
<!--   
  Favicon and App Icons
  <link rel="icon" type="image/x-icon" href="static/images/ABCD_page_icon.png">
  <link rel="apple-touch-icon" href="static/images/favicon.ico"> -->
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- MathJax for LaTeX support -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 1</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Adaptive Inference-Time Scaling via Cyclic Diffusion Search</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Gyubin Lee</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://mlml.kaist.ac.kr/219d50e9-3ef1-8073-b19b-c1e68e8cf905" target="_blank">Truong Nhat Nguyen Bao</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://jaesikyoon.com/" target="_blank">Jaesik Yoon</a><sup>1,4</sup>
                    </span>
                    <span class="author-block">
                    <a href="https://www.linkedin.com/in/dongwoo-%E2%80%8Dlee-7a5731225/?originalSubdomain=kr" target="_blank">Dongwoo Lee</a><sup>1</sup>, 
                    <a href="https://minsuukim.github.io/" target="_blank">Minsu Kim</a><sup>1,2</sup>, 
                    <a href="https://yoshuabengio.org/" target="_blank">Yoshua Bengio</a><sup>2</sup>, 
                    <a href="https://mlml.kaist.ac.kr/sungjinahn" target="_blank">Sungjin Ahn</a><sup>1,3</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>KAIST, <sup>2</sup>Mila, <sup>3</sup>NYU, <sup>4</sup>SAP<br>NeurIPS 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.14036.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.14036" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(TBD)</span>
                  </a>
                </span> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/ABCD_main_fig.png" alt="ABCD Main Figure" id="tree" style="width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
        
      </h2>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion models have demonstrated strong generative capabilities across domains ranging from image synthesis to complex reasoning tasks. However, most inference-time scaling methods rely on fixed denoising schedules, limiting their ability to allocate computation based on instance difficulty or task-specific demands adaptively. We introduce the challenge of adaptive inference-time scaling—dynamically adjusting computational effort during inference—and propose Adaptive Bi-directional Cyclic Diffusion (ABCD), a flexible, search-based inference framework. ABCD refines outputs through bi-directional diffusion cycles while adaptively controlling exploration depth and termination. It comprises three components: Cyclic Diffusion Search, Automatic Exploration-Exploitation Balancing, and Adaptive Thinking Time. Experiments show that ABCD improves performance across diverse tasks while maintaining computational efficiency.
          </p>
        </div>
        
        <h2 class="title is-3" style="margin-top: 3rem;">Background</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion Models show strong generative power. However, most inference-time scaling methods rely on fixed denoising schedules, limiting their ability to adapt computation based on instance difficulty or task-specific demands. This rigidity restricts performance on challenging inputs and can lead to inefficient spending of computation.
          </p>
          <p>
            <strong>Proposed Solution:</strong> We introduce the challenge of adaptive inference-time scaling—dynamically adjusting computational effort during inference—and propose the Adaptive Bi-directional Cyclic Diffusion (ABCD) framework.
          </p>
        
        <h2 class="title is-3" style="margin-top: 3rem;">Adaptive Bi-directional Cyclic Diffusion (ABCD)</h2>
        <div class="content has-text-justified">
          <p>
            ABCD reframes diffusion model inference as a flexible and efficient search process. The method is composed of three components, which operate in sequence during each iteration (or cycle) of the search:
          </p>

          <h4 class="title is-5"><strong>1. Cyclic Diffusion Search (CDS)</strong></h4>
          <p>
            Enables iterative refinement by cycling bi-directionally through the diffusion timeline. Each cycle consists of three stages:
          </p>
          <ul>
            <li><strong>Denoising:</strong> $N$ particles are quickly denoised from $t=T$ to $t=0$ using accelerated DDIM, yielding initial candidates $x_0$</li>
            <li><strong>Selection and Copy:</strong> Top-$K$ particles are selected using a reward function and replicated $J$ times</li>
            <li><strong>Noising:</strong> $K \times J$ particles are sent back to go-back timestep $t'$ via forward process $q(x_{t'}|x_0)$</li>
          </ul>
          
          <h4 class="title is-5"><strong>2. Automatic Exploration-Exploitation Balancing (AEEB)</strong></h4>
          <p>
            Dynamically controls exploration depth using a "temperature pool" $\mathcal{T}=(t_1, t_2, ..., t_M)$ instead of fixed go-back timesteps. $K \times J$ replicas are distributed across all temperatures, allowing parallel exploration at multiple depths. Suboptimal temperatures are automatically discarded in subsequent Top-$K$ selection.
          </p>
          
          <h4 class="title is-5"><strong>3. Adaptive Thinking Time (ATT)</strong></h4>
          <p>
            Provides principled stopping criterion by monitoring solution quality evolution. Termination occurs when all Top-$K$ particles originate from the lowest temperature ($t=0$) for $\kappa$ consecutive cycles, indicating that global exploration is no longer needed and the search has converged to local refinement.
          </p>
        </div>
        <div class="has-text-centered" style="margin-top: 2rem;">
          <img src="static/images/ABCD_Pseudo.png" alt="ABCD Pseudo Code" style="width: 100%; height: auto; max-width: 800px;">
        </div>
        
        <div class="has-text-centered">
          <h2 class="title is-3" style="margin-top: 3rem;">Experimental Results</h2>
        </div>
        <div class="content has-text-justified">
          <p>
            ABCD's effectiveness is demonstrated across a diverse suite of challenging tasks, showcasing superior performance and computational efficiency compared to fixed-schedule baselines: Standard base Diffusion, Best-of-N (BoN), Sequential Monte Carlo (SMC), Beam Search (BS), and Search over Path (SoP).
          </p>
          <figure class="has-text-centered" style="margin:0.1rem 0 0.6rem 0; max-width:800px; margin-left:auto; margin-right:auto;">
            <img id="exp-overview-fig" src="static/images/experiment_overall.png" alt="Experimental tasks overview" style="width:100%; height:auto; display:block;">
            <figcaption class="has-text-centered is-size-7" style="margin-top:0.1rem;">Figure: Experimental tasks overview</figcaption>
          </figure>
          <p>
            The experiments cover a wide range of tasks, including the Mixture of Gaussian (MoG) proof-of-concept, Sudoku Puzzle Completion, Pixel Maze Path Generation, OGBench Point Maze Navigation, QM9 Molecular 3D Structure Prediction, and Text-to-Image Generation. Overall, ABCD consistently achieves significant gains in performance and efficiency across all domains.
          </p>
        
          <h3 class="title is-4" style="margin-top: 2rem;">Key Experimental Findings</h3>
          
          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Mixture of Gaussian (MoG)</strong></h4>
          <p>
            The Mixture of Gaussian (MoG) toy task serves as a proof-of-concept to illustrate the necessity of multiple go-back noise levels and an adaptive terminal condition during iterative refinement. ABCD achieved a <strong>100% success rate</strong> and minimal final distance on both Dataset 1 (locally clustered modes) and Dataset 2 (distant modes).
          </p>
          <div class="has-text-centered" style="margin-top:1rem; margin-bottom:1rem;">
            <figure id="fig-mog-1" style="display:block; margin:0.5rem auto; max-width:80%;">
              <img src="static/images/MoG_D1_comparison.png" alt="MoG Figure 1" style="width:100%; height:auto; display:block;">
              <figcaption class="has-text-centered is-size-7" style="margin-top:0.35rem;">Figure 1: Compare different go-back step size on Dataset 1 (locally clustered modes).</figcaption>
            </figure>
            <figure id="fig-mog-2" style="display:block; margin:0.5rem auto; max-width:80%;">
              <img src="static/images/MoG_D2_comparison.png" alt="MoG Figure 2" style="width:100%; height:auto; display:block;">
              <figcaption class="has-text-centered is-size-7" style="margin-top:0.35rem;">Figure 2: Compare different go-back step size on Dataset 2 (distant modes).</figcaption>
            </figure>
            <figure id="fig-mog-3" style="display:block; margin:0.5rem auto; max-width:100%;">
              <img src="static/images/MoG_table.png" alt="MoG Figure 3" style="width:100%; height:auto; display:block;">
            </figure>
          </div>
          <ul style="margin-top:0.5rem; text-align: left;">
            <li><strong>Small go-back fails:</strong> Small GB (e.g., GB 20) cannot escape poor initial predictions on complex Dataset 2.</li>
            <li><strong>Large go-back risks:</strong> Large GB can over-cycle and diverge on easier Dataset 1, losing useful information.</li>
            <li><strong>Adaptive balance:</strong> ABCD adaptively balances exploration and exploitation, enabling effective scaling.</li>
          </ul>
          
          <h4 class="title is-4" style="margin-top: 2rem;">Overall Performance on Key Tasks</h4>
          <p>ABCD consistently delivered state-of-the-art results across various domains, showcasing superior time-accuracy trade-offs:</p>

          <figure class="has-text-centered" style="margin:0.1rem 0 0.6rem 0; max-width:800px; margin-left:auto; margin-right:auto;">
            <img id="exp-overview-fig" src="static/images/ABCD_full_results.png" alt="Experimental results overview" style="width:100%; height:auto; display:block;">
            <figcaption class="has-text-centered is-size-7" style="margin-top:0.1rem;">Figure: Experimental results overview</figcaption>
          </figure>

          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Sudoku Puzzle Completion</strong></h4>
          <p style="margin-top:0.25rem;">
            A logical reasoning benchmark requiring global exploration and local refinement. ABCD consistently outperforms all baselines, achieving <strong>100% accuracy</strong> on harder test sets while baselines (e.g., SoP) reach only 95.5%. It maintains stable accuracy across all difficulty levels.
          </p>
          
          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Pixel Maze Path Generation (OOD)</strong></h4>
          <p>
            Tests generalization to unseen, larger maze structures. ABCD achieves near-perfect success rates significantly faster than all baselines. The performance gap widens as maze size increases (Size 11-15), highlighting superior adaptive exploration capabilities.
          </p>
          
          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Molecular 3D Structure Prediction (QM9)</strong></h4>
          <p>
            Requires generating physically and chemically valid 3D conformations. ABCD significantly outperforms all baselines, achieving peak molecular stability of <strong>~0.99</strong> (vs. SoP's 0.94), emphasizing robustness in complex generation tasks.
          </p>
          
          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Text-to-Image Generation</strong></h4>
          <p>
            Evaluated on high-dimensional outputs using compressibility and aesthetic scores. ABCD consistently outperforms BoN and SoP, efficiently identifying high-reward samples. ABCD achieves the same compression level that SoP reaches at 272s in less than a quarter of the time.
          </p>

          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>OGBench Point Maze Navigation</strong></h4>
          <p>
            A long-horizon planning task (1000+ steps). ABCD consistently surpassed all baselines and was the only method to achieve perfect performance on both Large and Giant mazes.
          </p>
          

          <h3 class="title is-4" style="margin-top: 2rem;">Ablation Studies</h3>
          <p>Ablation studies confirm the effectiveness and necessity of ABCD's adaptive components. Key findings are summarized below.</p>

          <figure class="has-text-centered" style="margin:0.1rem 0 0.6rem 0; max-width:800px; margin-left:auto; margin-right:auto;">
            <img id="exp-overview-fig" src="static/images/Ablation_overall.png" alt="Ablation studies overview" style="width:100%; height:auto; display:block;">
            <figcaption class="has-text-centered is-size-7" style="margin-top:0.1rem;">Figure: Ablation studies overview</figcaption>
          </figure>
          
          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Task-Specific Optimal Exploration Depth (a)~(b)</strong></h4>
          <p>
            The optimal go-back noise level for iterative refinement varies substantially by task. For example, the best go-back step size was observed to be approximately 3/4 of total denoising steps for OGBench, 2/5 for Sudoku, and 4/5 for Pixel Maze. This variation motivates ABCD's Automatic Exploration–Exploitation Balancing (AEEB), which probes multiple exploration depths in parallel to find task-specific optimal depths.
          </p>

          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Adaptive Terminal Condition Necessity (c)</strong></h4>
          <p>
            An ablation on terminal criteria shows that using an adaptive stopping rule substantially improves overall time–success trade-offs by avoiding wasted computation on easy instances while allocating additional cycles to difficult ones. The adaptive terminal condition therefore plays a critical role in ABCD's efficiency.
          </p>

          <h4 class="title is-5" style="margin-bottom:0.25rem;"><strong>Dynamic Compute Allocation (Adaptive Thinking Time) (d)</strong></h4>
          <p>
            ABCD's Adaptive Thinking Time (ATT) criterion automatically scales computational effort to instance difficulty. Harder instances (smaller number provided case) receive more thinking cycles while simpler instances (more number provided case) terminate earlier, producing consistently superior time–success trade-offs compared to fixed-cycle baselines.
          </p>

          <h4 class="title is-5" style="margin-bottom:0.5rem;"><strong>Adaptive Exploration and Refinement Mechanism</strong></h4>
          <figure class="has-text-centered" style="margin:0.1rem 0 0.6rem 0; max-width:800px; margin-left:auto; margin-right:auto;">
            <img id="exp-overview-fig" src="static/images/particle_sources.png" alt="Ablation studies overview" style="width:100%; height:auto; display:block;">
            <figcaption class="has-text-centered is-size-7" style="margin-top:0.1rem;">Figure: Origin of the Top-10 Selected Particles at Each Cycle</figcaption>
          </figure>
          
          <p>
            The image describes the mechanism by which the Adaptive Bi-directional Cyclic Diffusion (ABCD) model dynamically controls the balance between global exploration and local refinement across inference cycles. This mechanism is crucial for achieving high performance with optimal computational efficiency, especially in complex reasoning tasks like Sudoku.  
          </p>
          <ul style="margin-top:0.5rem; text-align: left;">
            <li><strong>Behavior Varies by Difficulty:</strong> The search behavior varies significantly across Sudoku cases. Harder instances (fewer provided clues) generally tend to require a longer search (more cycles).</li>
            <li><strong>Dynamic Exploration/Exploitation:</strong> Early Iterations focus on large modifications (corresponding to higher go-back temperatures/larger noise addition), emphasizing global exploration. Later Cycles concentrate on smaller refinements (corresponding to lower go-back temperatures/less noise addition), shifting toward local exploitation.</li>
            <li><strong>Instance-Specific Graph:</strong> This dynamic adjustment means the model automatically expands and adjusts the diffusion generation process, resulting in a different generation graph for each final $x_0$ prediction.</li>
          </ul>

          <h3 class="title is-4" style="margin-top: 2rem;">Conclusion</h3>
          <p>This work addresses the critical limitation of fixed computational allocation in Diffusion Models by introducing the challenge of Adaptive Inference-Time Scaling. We proposed Adaptive Bi-directional Cyclic Diffusion (ABCD), a flexible, search-based inference framework that dynamically adjusts computational effort.</p>


        </div>
      </div>
    </div>
  </div>
</section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@misc{lee2025adaptiveinferencetimescalingcyclic,
      title={Adaptive Inference-Time Scaling via Cyclic Diffusion Search}, 
      author={Gyubin Lee and Truong Nhat Nguyen Bao and Jaesik Yoon and Dongwoo Lee and Minsu Kim and Yoshua Bengio and Sungjin Ahn},
      year={2025},
      eprint={2505.14036},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2505.14036}, 
}</code></pre>
    </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
  </html>
